# NLP Lab 4

This repository contains the code and resources for the NLP Lab 4 project ,

## Objective

The main objective of this project is to familiarize ourselves with Natural Language Processing (NLP) language models using the Pytorch library. The project includes tasks such as classification, regression, text generation, and utilization of pre-trained models like GPT2 and BERT.

## Project Structure

The project is divided into three main parts:

### Part 1: Classification Regression

In this part, we collect text data from Arabic websites, preprocess it, and train various models including RNN, Bidirectional RNN, GRU, and LSTM architectures for classification and regression tasks.

### Part 2: Transformer (Text Generation)

Here, we install and fine-tune the GPT2 pre-trained model for text generation tasks. We generate new paragraphs based on given sentences.

### Part 3: BERT

Utilizing the pre-trained bert-base-uncased model, we prepare data, adapt the BERT Embedding Layer, fine-tune the model, and evaluate its performance using various metrics.


## Tools Used

- Google Colab or Kaggle
- GitLab/GitHub
- Spacy
- NLTK
- Pytorch

Feel free to explore each part of the project and contribute!

