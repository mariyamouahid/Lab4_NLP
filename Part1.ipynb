{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad27f9cd",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;text-align:center;\">Lab4 - Part 1</h1>\n",
    "\n",
    "<hr style=\"border:2px solid blue;\">\n",
    "\n",
    "<h3 style=\"color:blue;\">Realised by: <strong style=\"color:black;\">Ouahid Mariyam</strong></h3>\n",
    " \n",
    "\n",
    "<h3 style=\"color:blue;\">Guided by: <strong style=\"color:black;\">Pr . ELAACHAk LOTFI</strong></h3> \n",
    "   \n",
    "\n",
    "<p><strong>Objective :</strong> The main purpose behind this lab is to get familiar with NLP language models\n",
    "using Pytorch library.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b1ae4",
   "metadata": {},
   "source": [
    "# Summary: Part 1\n",
    "\n",
    "1. [Part 1: Classification Regression](#part-1)\n",
    "    1. [Data Collection](#col)\n",
    "    2. [Data Preprocessing](#pre)\n",
    "    3. [Model Training](#tra)\n",
    "    4. [Model Evaluation](#eva)\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e671f43",
   "metadata": {},
   "source": [
    "# Part 1: Classification Regression <a id='part-1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee95731",
   "metadata": {},
   "source": [
    "## A. Data Collection <a id='col'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d2aff",
   "metadata": {},
   "source": [
    "We use web scraping libraries such as Scrapy or BeautifulSoup to collect text data from Arabic websites related to a specific topic. Each text is assigned a relevance score between 0 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69681566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499643dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection\n",
    "urls = [\n",
    "    'https://www.who.int/ar/news/item/17-07-1445-who-awards-countries-for-progress-in-eliminating-industrially-produced-trans-fats-for-first-time',\n",
    "    'https://www.who.int/ar/news/item/17-08-1444-massive-efforts-needed-to-reduce-salt-intake-and-protect-lives',\n",
    "    'https://www.who.int/ar/news/item/26-12-1444-aspartame-hazard-and-risk-assessment-results-released'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b28cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    text = ' '.join([p.get_text(strip=True) for p in paragraphs])\n",
    "    return text\n",
    "\n",
    "texts = [scrape_url(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c6db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 (Score: 6):\n",
      "منحت منظمة الصحة العالمية (المنظمة) خمسة بلدان أولى شهادات على الإطلاق تصادق على إحراز التقدم في التخلّص من الدهون المتحوّلة المنتجة صناعياً. فقد أثبتت كل من الدانمرك وليتوانيا وبولندا والمملكة العربية السعودية وتايلند تنفيذها لسياسات بشأن أفضل الممارسات المتبعة في التخلّص من الدهون المتحوّلة المنتجة صناعياً (الدهون المتحوّلة) مدعومة بما يلزم من نظم لرصد السياسات وإنفاذها. كما أصدرت المنظمة نتائج مستمدة من السنوات الخمس الأولى لتنفيذمبادرتهاREPLACEللتخلّص من الدهون المتحوّلة. ومع أن الغاية الطموحة التي حددتها المنظمة في عام 2018 - للتخلّص تماماً من الدهون المتحوّلة في إمدادات الأغذية العالمية بحلول عام 2023 – هي غاية لم تُبلغ، فقد أُحرِزَ تقدم ملحوظ صوب بلوغها في كل إقليم من أقاليم العالم. ونُفّذت في عام 2023 لوحده سياسات جديدة بشأن أفضل الممارسات في 7 بلدان (هي مصر والمكسيك ومولدوفا ونيجيريا ومقدونيا الشمالية والفلبين وأوكرانيا). والدهون المتحوّلة هي دهون يتراوح قوامها بين شبه الصلب والصلب وتتخذ شكلين اثنين هما: الدهون المنتجة صناعياً وتلك الطبيعية. ويرتبط مدخول الفرد من هذه الدهون بزيادة خطورة الإصابة بالنوبات القلبية والوفاة بسبب أمراض القلب. وليس لهذه الدهون فوائد صحية معروفة، وغالباً ما تكون الأطعمة الحاوية على كميات كبيرة منها (مثل الأطعمة المقلية والكعك والوجبات الجاهزة) حاوية أيضاً على كميات كبيرة من السكر والدهون والملح. ويوجد إجمالاً 53 بلداً لديها الآن سياسات معمول بها بشأن أفضل الممارسات لمعالجة الدهون المتحوّلة في الأغذية، ممّا يحسّن بشكل كبير البيئة الغذائية لنحو 3,7 مليار شخص، أو نسبة 46٪ من سكان العالم مقارنة بنسبة 6٪ قبل 5 سنوات فقط. ومن المتوقع أن تنقذ تلك السياسات أرواح 000 183 شخص سنوياً. وتحدث الدكتور تيدروس أدحانوم غيبريسوس، المدير العام للمنظمة، قائلاً: \"إن الدهون المتحوّلة ليس لها فوائد صحية معروفة ولكن مخاطرها الصحية جسيمة. ونحن سعداء للغاية لأن بلداناً كثيرة جداً قد وضعت سياسات تحظر استعمال الدهون المتحوّلة أو تحد من استعمالها في الأغذية. ولكن وضع السياسات شيء؛ وتنفيذها شيء آخر. وإنني أهنئ الدانمرك وليتوانيا وبولندا والمملكة العربية السعودية وتايلند التي تتولى قيادة العالم في مجال رصد وإنفاذ سياساتها المتعلقة بالتخلّص من الدهون المتحوّلة، كما نحث الدول الأخرى على أن تحذو حذوها\". ومن شأن تسريع وتيرة الجهود الرامية إلى تطبيق سياسات بشأن أفضل الممارسات في 8 بلدان فقط تمس حاجتها إليها أن يؤدي إلى التخلّص من نسبة 90٪ من العبء العالمي للدهون المتحوّلة، ممّا يمثل فرصة فريدة من نوعها لنشهد في حياتنا عالماً خالياً من الوفيات الناجمة عن تلك الدهون. ويعرب برنامج المنظمة بشأن المصادقة على التخلّص من الدهون المتحوّلة عن تقديره لجهود البلدان التي ذهبت إلى ما هو أبعد من وضع سياسات بشأن أفضل الممارسات من خلال ضمان تنفيذ نظم صارمة لرصد تلك السياسات وإنفاذها. ولا غنى عن رصد الامتثال للسياسات وإنفاذها لتعظيم الفوائد الصحية للتخلّص من الدهون المتحوّلة وصونها. وتطبّق أفضل الممارسات المبينة في سياسات التخلّص من الدهون المتحوّلة معايير المنظمة وتحد من استعمال تلك الدهون في كل المواضع. وتشتمل السياسات الموضوعة بشأن أفضل الممارسات على خيارين اثنين، هما: 1) تعيين عتبة وطنية إلزامية لتحديد كمية الدهون المتحوّلة بمقدار غرامين اثنين لكل 100 غرام من الدهون إجمالاً في جميع الأطعمة. 2) وفرض حظر وطني إلزامي على إنتاج الزيوت المهدرجة جزئياً أو استعمالها (وهي مصدر رئيسي للدهون المتحوّلة) بوصفها من مكونات جميع الأطعمة. ولعل الخيار الأمثل في بعض البلدان هو تطبيق السياستين كلتيهما بسبب مصادر الدهون المتحوّلة. وتحدث الدكتور توم فريدن، رئيس مبادرة عازمون على إنقاذ الأرواح (Resolve to Save Lives) ومديرها التنفيذي، قائلاً: \"إن التخلّص من الدهون المتحوّلة أمر مجدٍ اقتصادياً وسياسياً وتقنياً وهو ينقذ الأرواح من دون أن يكبد الحكومات أو المستهلكين أي تكلفة تقريباً. فهذا المركب الضار لا داعي له ولن يفتقده أي أحد عندما يختفي. وإننا في طريقنا إلى كسب معركتنا ضد الدهون المتحوّلة، ولكن البلدان التي ليس لديها لوائح معرضة لخطر أن تصبح مكبات للمنتجات الحاوية على تلك الدهون، وعليه تقع على عاتق الحكومات ودوائر صناعة الأغذية مسؤولية ضمان عدم حدوث ذلك\". كما تشجع المنظمة مصنعي الأغذية - منتجو المواد الخام والمنتجات الغذائية النهائية - على التخلّص من الدهون المتحوّلة في منتجاتهم. وقد أحرزت دوائر صناعة الأغذية تقدماً جيداً حتى الآن، مثلما جاء فيتقرير صدر عن المنظمة في تشرين الثاني/نوفمبر 2023. ورغم ما تحقق مؤخراً من نجاحات في مجال التخلّص من الدهون المتحوّلة في الأغذية على صعيد العالم، فإن أكثر من نصف سكان العالم ما زالوا غير محميين من آثارها الضارة، ممّا يعرضهم لاحتمال زيادة خطورة الإصابة بأمراض القلب. ومع أنه ينبغي أن تواصل البلدان سعيها جاهدة إلى التخلّص تماماً من الدهون المتحوّلة بناءً على ما تحقق خلال السنوات الخمس منذ توجيه الدعوة العالمية بشأن التخلّص من تلك الدهون، فإن المنظمة تقترح غاية جديدة منقحة بشأن التخلّص فعلياً من الدهون المتحوّلة على الصعيد العالمي بحلول عام 2025، وهي غاية تفيد بما يلي: والتخلّص من الدهون المتحوّلة وسيلة قوية للوقاية من أمراض القلب والتكاليف الباهظة التي يتكبدها الأفراد والاقتصادات بسبب توفير العلاج الطبي وفقدان الإنتاجية. وتظل المنظمة ملتزمة بدعم البلدان في جهودها والاحتفاء بإنجازاتها. وستُفتح في آذار/مارس 2024 الدورة المقبلة من تقديم الطلبات إلى برنامج المصادقة على التخلّص من الدهون المتحوّلة وسيتواصل تلقي الطلبات باستمرار. أقامت منظمة الصحة العالمية شراكة مع مبادرة عازمون على إنقاذ الأرواح (Resolve to Save Lives)، وهي منظمة غير ساعية إلى الربح، لدعم عملية وضع وتنفيذحزمة إجراءات للتخلّص من الدهون المُتحوّلة المُنتجة صناعياً في إمدادات الأغذية العالمية (حزمة إجراءات REPLACE). وتوفر هذه الحزمة الصادرة عن المنظمة والمُدشنة في عام 2018، نهجاً استراتيجياً للتخلص من الدهون المتحوّلة المنتجة صناعياً في الإمدادات الغذائية الوطنية. وقد دأبتمؤسسة بلومبرغ الخيريةمنذ عام 2017 على دعم الجهود العالمية التي تبذلها مبادرة عازمون على إنقاذ الأرواح لإنقاذ أرواح الناس من أمراض القلب والأوعية الدموية. ولمعرفة المزيد، يُرجى زيارة الرابط التالي:https://www.resolvetosavelives.org  لتوجيه الاستفسارات الصحفية العامة،press@resolvetosavelives.org للاتصال الإعلامي استفسارات وسائل الإعلام  Steven Chlapecka Resolve to Save Lives صحيفة وقائع\n",
      "\n",
      "Text 2 (Score: 7.5):\n",
      "يبيّن تقريرٌ عالمي صادر عن منظمة الصحة العالمية (المنظمة) بشأن تقليل مدخول الصوديوم، وهو أول تقرير من نوعه، أن العالم قد خرج عن المسار الصحيح لتحقيق غايته العالمية المتمثلة في تقليل مدخول الصوديوم بنسبة 30٪ بحلول عام 2025. ويتسبّب الصوديوم، وهو من المغذيات الأساسية، في زيادة خطر الإصابة بالأمراض القلبية مثل السكتة والوفاة المبكرة في حال الإفراط في تناوله. ويتمثل المصدر الرئيسي للصوديوم في ملح المائدة (كلوريد الصوديوم)، ولكنه يوجد أيضاً في توابل أخرى مثل غلوتامات الصوديوم. ويبيّن التقرير أن 5٪ فقط من الدول الأعضاء في المنظمة تحظى بحماية سياسات إلزامية شاملة للحد من الصوديوم وأن 73٪ من الدول الأعضاء في المنظمة تفتقر إلى النطاق الكامل لتنفيذ هذه السياسات. ومن شأن تنفيذ سياسات عالية المردودية لتقليل مدخول الصوديوم أن ينقذ أرواح ما يقدر بنحو 7 ملايين شخص في العالم بحلول عام 2030، ويعد من العناصر الهامة للعمل الرامي إلى تحقيق غاية أهداف التنمية المستدامة المتمثلة في الحد من الوفيات الناجمة عن الأمراض غير السارية. ولكن، هناك تسعة بلدان فقط (البرازيل وشيلي والجمهورية التشيكية وليتوانيا وماليزيا والمكسيك والمملكة العربية السعودية وإسبانيا وأوروغواي) لديها مجموعة شاملة من السياسات الموصى بها لتقليل مدخول الصوديوم في الوقت الراهن. وقال الدكتور تيدروس أدحانوم غيبريسوس، المدير العام للمنظمة: \"تعد النظم الغذائية غير الصحية من الأسباب الرئيسية للوفاة والمرض في العالم، ويشكل الإفراط في تناول الصوديوم أحد المسبّبات الرئيسية. ويبيّن هذا التقرير أن معظم بلدان العالم لم تعتمد بعد أي سياسات إلزامية لتقليل مدخول الصوديوم، مما يجعل شعوبها عرضة لخطر الإصابة بالنوبات القلبية والسكتات وغيرها من المشاكل الصحية. وتدعو المنظمة جميع البلدان إلى تنفيذ \"أفضل الخيارات\" لتقليل مدخول الصوديوم، كما تدعو المصنعين إلى تنفيذ معايير المنظمة المتعلقة بمحتوى الأغذية من الصوديوم\". ويتضمن النهج الشامل لتقليل مدخول الصوديوم اعتماد السياسات الإلزامية وتدخلات المنظمة الأربعة المتعلقة بالصوديوم التي تمثل أفضل الخيارات والتي تسهم بشكل كبير في الوقاية من الأمراض غير السارية. وتشمل هذه التدخلات ما يلي: 1- إعادة تركيب الأغذية لتحتوي على كمية أقل من الملح، وتحديد غايات لكمية الصوديوم في الأغذية والوجبات 2- وضع سياسات عامة لشراء الأغذية ترمي إلى الحد من الأغذية الغنية بالملح أو الصوديوم في المؤسسات العامة مثل المستشفيات والمدارس وأماكن العمل ودور الرعاية 3- توسيم واجهة العبوات لمساعدة المستهلكين على اختيار منتجات تحتوي على كمية أقل من الصوديوم 4- تنظيم حملات تواصُل لتغيير السلوك وحملات إعلامية جماهيرية للحد من استهلاك الملح/ الصوديوم وتُشجَّع البلدان على وضع غايات بشأن محتوى الأغذية المجهّزة من الصوديوم، تمشياً مع معايير الصوديوم العالمية للمنظمة، وإنفاذها من خلال تلك السياسات. وتعد السياسات الإلزامية لتقليل مدخول الصوديوم أكثر فعالية لأنها تحقق تغطية أوسع نطاقاً وتحمي من المصالح التجارية، وتتيح في الوقت نفسه فرصا متكافئة لمصنعي الأغذية. وقد وضعت المنظمة، في إطار التقرير،سجل أداء قُطري بشأن الصوديومللدول الأعضاء يقوم على أساس نوع وعدد سياسات تقليل مدخول الصوديوم التي وضعتها. وقال الدكتور توم فريدن، الرئيس والمدير التنفيذي لمبادرة \"العزم على إنقاذ الأرواح\"، وهي مؤسسة غير ربحية تعمل مع البلدان على تلافي 100 مليون حالة وفاة بسبب الأمراض القلبية الوعائية على مدى 30 عاما: \"يبيّن هذا التقرير الهام بوضوح أنه يجب على البلدان أن تعمل بشكل عاجل على تنفيذ سياسات طموحة وإلزامية لتقليل مدخول الصوديوم تقودها الحكومات من أجل بلوغ الغاية العالمية المتمثلة في الحد من استهلاك الملح بحلول عام 2025. وهناك تدابير مثبتة يمكن للحكومات تنفيذها، فضلاً عن ابتكارات هامة مثل الأملاح ذات المحتوى المنخفض من الصوديوم. ويلزم على العالم أن يتخذ إجراءات على الفور وإلا فسيُصاب عدد أكبر من الأشخاص بنوبات قلبية وسكتات مُسبّبة للإعاقة أو مميتة، والتي يمكن الوقاية منها\". ويُقدَّر المتوسط العالمي لمدخول الملح بنحو 10,8 غرامات يومياً، وهي كمية تزيد بأكثر من الضعف على تلك المحددة في توصية المنظمة والمتمثلة في أقل من 5 غرامات من الملح يومياً (ملعقة صغيرة واحدة). ويمثل الإفراط في تناول الملح عامل الخطر الرئيسي للوفيات المرتبطة بالنظام الغذائي والتغذية. ويظهَر في الوقت الراهن المزيد من البيّنات التي توثق الروابط بين ارتفاع مدخول الصوديوم وزيادة خطر الإصابة بحالات صحية أخرى مثل سرطان المعدة والسمنة وتَخلخُل العظام وأمراض الكلى. وتدعو المنظمة الدول الأعضاء إلى تنفيذ سياسات لتقليل مدخول الصوديوم على الفور وإلى التخفيف من الآثار الضارة الناجمة عن الاستهلاك المفرط للملح. كما تدعو مصنعي الأغذية إلى وضع غايات طموحة لتقليل مدخول الصوديوم في منتجاتهم. وللاطلاع على التقرير، يرجى زيارة الموقع التالي:https://www.who.int/publications/i/item/9789240069985 أقامت المنظمة شراكة مع مبادرة \"العزم على إنقاذ الأرواح\"، وهي مؤسسة غير ربحية، لغرض دعم بلدان العالم في الحد من استهلاك السكان للصوديوم. ونشرت مبادرة \"العزم على إنقاذ الأرواح\" مؤخراًقاعدة بيانات عالمية بشأن التغذية خاصة بالأغذية المعبّأةتتضمن حالياً بيانات عن العناصر الغذائية للأغذية المعبّأة لما مجموعه 25 بلداً. وتدعم مؤسسة بلومبرغ الخيرية، منذ عام 2017، الجهود العالمية التي تبذلها مبادرة \"العزم على إنقاذ الأرواح\" من أجل إنقاذ الأرواح من الأمراض القلبية الوعائية. ولمزيد من المعلومات، يرجى زيارة الموقع https://www.resolvetosavelives.org أو Twitter @ResolveTSL للاتصال الإعلامي Ni Jin مسؤولة اتصالاتمكتب منظمة الصحة العالمية في أفغانستان Steven Chlapecka Resolve to Save Lives\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example manual scoring (adjust according to text relevance)\n",
    "scored_texts = [(texts[0], 6), (texts[1], 7.5)]\n",
    "\n",
    "# Displaying the collected and scored texts\n",
    "for i, (text, score) in enumerate(scored_texts):\n",
    "    print(f'Text {i+1} (Score: {score}):\\n{text}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b04d4",
   "metadata": {},
   "source": [
    "## B. Data Preprocessing <a id='pre'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad252af",
   "metadata": {},
   "source": [
    "We establish an NLP pipeline for preprocessing the collected dataset. This pipeline includes tokenization, stemming, lemmatization, removal of stop words, and possibly discretization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ade986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = SnowballStemmer('arabic')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(stopwords.words('arabic'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in stemmed_tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Preprocess the texts\n",
    "preprocessed_texts = [preprocess_text(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c919ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Text 1:\n",
      "منح منظم الصح عالم منظم لدا اولى شهاد اطلاق تصادق احراز تقدم الده منتج فقد اثب دانمرك يتوان ولند مملك عرب سعود تايلند تنفيذ سياس بشء افضل ممارس متبع الده منتج الده مدعوم يلزم نظم لرصد سياس انفاذ اصدر منظم نتايج مستمد سنو خمس اولى الده ومع الغا طموح حدد منظم عام الده امداد اغذ عالم حلول عام غا فقد تقدم ملحوظ صوب لوغ اقليم اقاليم عالم عام لوحد سياس جديد بشء افضل ممارس لدا مصر مكس مولدوف نيجير مقدون شمال فلب اوكران والده دهو يتراوح قوام صلب صلب تتخذ شكل الده منتج وتل طبيع يرتبط مدخول فرد الده زياد خطور اصاب نوب قلب وفا سبب امراض قلب ليس لهذ الده وايد صح تكو اطعم حاو كم كبير اطعم مقل والكع وجب جاهز حاو كم كبير سكر والده ملح يوجد لد سياس معمول بشء افضل ممارس معالج الده شكل كبير بيء غذاء لنح مليار نسب سكا عالم مقارن نسب سنو فقط متوقع تنقذ سياس ارواح شخص تحدث دكتور تيدروس ادحانوم مدير عام الده وايد صح معروف مخاطر الصح جسيم ونح سعداء للغا لان كثير وضع سياس تحظر استعمال الده تحد استعمال اغذ وضع سياس تنفيذ شيء اخر وان اهنء دانمرك يتوان ولند مملك عرب سعود تايلند تتولى قياد عالم مجال رصد انفاذ سياس متعلق الده نحث دول اخرى تحذ حذو شان تسريع تير جهود رام تطبيق سياس بشء افضل ممارس لدا فقط تمس حاج ال يود نسب عبء عالم للده يمثل فرص ريد نوع نشهد حيا الوف ناجم الده يعرب رنامج منظم بشء مصادق الده تقدير جهود بلد ذهب ابعد وضع سياس بشء افضل ممارس خلال ضما تنفيذ نظم صارم لرصد سياس انفاذ غنى رصد امتثال سياس انفاذ تعظيم فوايد الصح الده وصو افضل ممارس مبين سياس الده معايير منظم تحد استعمال الده مواضع تشتمل سياس موضوع بشء افضل ممارس خيار تع عتب وطن الزام تحديد كم الده مقدار غرام لكل غرام الده اطعم فرض حظر وطن الزام انتاج الز مهدرج استعمال وه مصدر رييس للده وصف مكون اطعم لعل خيار امثل بلد تطبيق سياست كلت سبب مصادر الده تحدث دكتور توم رييس مبادر عازم انقاذ ارواح resolve to save life مدير الده امر ينقذ ارواح يكبد حكوم مستهلك تكلف فهذ مركب ضار داع ولن يفتقد عندم يختف وان طريق كسب معر ضد الده بلد لد وايح معرض لخطر تصبح مكب منتج حاو وعل تقع عاتق حكوم دواير صناع اغذ مسوول ضما عدم حدوث تشجع منظم مصنع اغذ منتج مواد خام منتج غذاء نهاء الده منتج وقد احرز دواير صناع اغذ مثلم جاء يتقرير صدر منظم رغم تحقق نجاح مجال الده اغذ صعيد نصف سكا عالم زالو محم اثار يعرض احتمال زياد خطور اصاب امراض قلب ومع انه ينبغ تواصل بلد سع جاهد الده تحقق خلال سنو خمس توج دعو عالم بشء منظم تقترح غا جديد منقح بشء الده صعيد عالم حلول عام وه غا تفيد يل الده سيل قو وقا امراض قلب تكاليف باهظ يتكبد افراد اقتصاد سبب توفير علاج الطب فقد انتاج تظل منظم ملتزم دعم بلد جهود احتفاء انجاز دور مقبل تقديم طلب رنامج مصادق الده سيتواصل تلق طلب استمرار اقام منظم الصح عالم شراك مبادر عازم انقاذ ارواح resolve to save life وه منظم ساع لدعم عمل وضع تنفيذحزم اجراء الده امداد اغذ عالم حزم اجراء replace توفر حزم صادر منظم عام تخلص الده منتج امداد غذاء وطن وقد دابتموسس لومبرغ خيريةمنذ عام دعم جهود عالم تبذل مبادر عازم انقاذ ارواح انقاذ ارواح ناس امراض قلب اوع دمو معرف زيار رابط تال http لتوج استفسار صحف اتصال اعلام استفسار سايل اعلام steven chlapecka resolve to save life صحيف قايع\n",
      "\n",
      "Preprocessed Text 2:\n",
      "عالم صادر منظم الصح عالم منظم بشء تقليل مدخول تقرير عالم خرج مسار صحيح تحقيق غا عالم متمثل تقليل مدخول صوديوم نسب حلول عام مغذ زياد خطر اصاب امراض قلب سكت وفا مبكر حال افراط تناول يتمثل مصدر رييس صوديوم ملح مايد لوريد صوديوم ولك يوجد توابل اخرى غلوتام صوديوم تقرير فقط دول اعضاء منظم تحظى حما سياس الزام شامل للحد صوديوم وان دول اعضاء منظم تفتقر نطاق كامل تنفيذ سياس شان تنفيذ سياس عال مردود تقليل مدخول صوديوم ينقذ ارواح يقدر بنح ملا شخص عالم حلول عام يعد عناصر هام عمل رام تحقيق غا اهداف تنم مستدام متمثل الحد الوف ناجم امراض سار لدا فقط برازيل شيل جمهور تشيك يتوان ماليز مكس مملك عرب سعود اسبان اوروغو لد مجموع شامل سياس موصى تقليل مدخول صوديوم الو راه قال دكتور تيدروس ادحانوم مدير عام منظم تعد نظم غذاء الصح اسباب رييس وفا مرض يشكل افراط تناول صوديوم رييس تقرير معظم لدا عالم تعتمد سياس الزام تقليل مدخول يجعل شعوب عرض لخطر اصاب نوب قلب سكت غير مشاكل الصح تدع منظم بلد تنفيذ افضل خيار تقليل مدخول تدع مصنع تنفيذ معايير منظم متعلق محتوى اغذ صوديوم يتضم نهج شامل تقليل مدخول صوديوم اعتماد سياس الزام تدخل منظم اربع متعلق صوديوم تمثل افضل خيار وال تسهم شكل كبير وقا امراض سار تشمل تدخل يل اعاد تركيب اغذ لتحت كم تحديد غا لكم صوديوم اغذ وجب وضع سياس شراء اغذ ترم الحد اغذ الغن ملح صوديوم موسس عام مستشف مدارس وام عمل دور رعا توسيم واجه عبو مساعد مستهلك اختيار منتج تحتو كم صوديوم تنظيم حمل تغيير سلوك حمل اعلام جماهير للحد استهل صوديوم بلد وضع غا بشء محتوى اغذ معايير صوديوم عالم انفاذ خلال سياس تعد سياس الزام تقليل مدخول صوديوم عال لان تحقق تغط اوسع تحم مصالح تتيح الو نفس فرص متكافء مصنع اغذ وقد وضع اطار اداء بشء صوديومللدول اعضاء يقوم اساس نوع عدد سياس تقليل مدخول صوديوم وضع قال دكتور توم رييس مدير تنفيذ مبادر عزم انقاذ ارواح وه موسس ربح تعمل بلد تلاف مليو حال وفا سبب امراض قلب وعاء مدى عام تقرير هام وضوح انه يجب بلد تعمل شكل عاجل تنفيذ سياس طموح الزام تقليل مدخول صوديوم تقود حكوم لوغ الغا عالم متمثل الحد استهل ملح حلول عام وهن تدابير مثبت يمك حكوم ابتكار هام املاح محتوى منخفض صوديوم يلزم عالم يتخذ اجراء فور وال عدد اكبر اشخاص نوب قلب سكت اعاق وال يمك وقا متوسط عالم مدخول ملح بنح غرام وه كم تزيد اكثر ضعف محدد توص منظم متمثل غرام ملح ملعق صغير واحد يمثل افراط تناول ملح عامل خطر رييس للوف مرتبط نظام غذاء تغذ الو راه مزيد توثق روابط ارتفاع مدخول صوديوم زياد خطر اصاب حال صح اخرى سرطا معد سمن عظام امراض كلى تدع منظم دول اعضاء تنفيذ سياس تقليل مدخول صوديوم فور الى تخفيف اثار ضار ناجم استهلاك مفرط ملح تدع مصنع اغذ وضع غا طموح تقليل مدخول صوديوم منتج اطلاع يرجى زيار موقع تال http اقام منظم شراك مبادر عزم انقاذ ارواح وه موسس لغرض دعم لدا عالم الحد استهل السك صوديوم نشر مبادر عزم انقاذ ارواح يان عالم بشء تغذ اغذ يان عناصر غذاء اغذ مجموع تدعم موسس لومبرغ عام جهود عالم تبذل مبادر عزم انقاذ ارواح انقاذ ارواح امراض قلب وعاء مزيد يرجى زيار موقع http twitter resolvetsl اتصال اعلام ni jin مسوول اتصالاتمكتب منظم الصح عالم افغانست steven chlapecka resolve to save life\n",
      "\n",
      "Preprocessed Text 3:\n",
      "اصدر يومالوكال دول بحوث سرط منظم الصح عالم منظم لجن خبراء مشترك منظم اغذ زراع منظم الصح عالم معن مواد مضاف اغذ لجن خبراء مشترك نتايج تقييم اثار الصح سكر وكال دول بحوث سرط اسبارتام انه محتمل يكو بشر مجموع تصنيف وكال محدود طابع اكد لجن خبراء مشترك مدخول يوم مقبول بالغ مغ لكل كغ وزن جسم اسبارتام اصطناع يمياء نطاق واسع مختلف منتج اغذ مشروب ثمانين قرن مشروب منتج الب حبوب معج ادو قرص فيتامين قابل مضغ قال دكتور رانشيس مدير ادار تغذ سلام اغذ منظم يعد سرط اسباب رييس وفا عالم فكل يمو شخص اشخاص سبب سرط يتطور علم استمرار غرض تقييم عوامل محتمل سرط اصاب امل خفض ارقام والحد خساير بشر واستطرد اظهر تقييم اسبارتام انه رغم جرع شايع استعمال تشكل مصدر قلق كبير انه لوحظ اثار محتمل يلزم تحقيق طريق اجراء مزيد دراس نوع افضل اجر هييت استعراض مستقل ولك متكامل هدف تقييم خطر سرطن محتمل غير مخاطر الصح مرتبط استهل اسبارتام وهذ المر اولى تجر وكال دول بحوث سرط اسبارتام والمر ثالث نسب للجن خبراء مشترك عقب استعراض مولف علم اظهر تقييم جود نقايص متاح دال اصاب سرط غير اثار الصح وكال دول بحوث سرط اسبارتام انه محتمل يكو بشر مجموع محدود اصاب بشر سرط سرطا الخل كبد نوع انواع سرطا كبد كان محدود اصاب حيوان تجارب سرط محدود يتعلق الال محتمل سرط خلص لجن خبراء مشترك بيان خضع تقييم تشير جود سبب تعديلمدخول اسبارتام يوم مقبول محدد يتراوح مغ لكل كغ وزن جسم اكد لجن انه مام فرد يستهل اسبارتام ضمن حدود يوم على سبيل يتجاوز شخص بالغ يزن كغ مدخول يوم مقبول يلزم يستهل علب مشروب الحم غاز محتو مغ اسبارتام افتراض انه يوجد مدخول اخر مصادر غذاء اخرى تشكل عمل تحديد اخطار تجر وكال دول بحوث خطو اساس اولى لفهم طابع مسرط خلال تحديد خصايص قدر الحاق سرط تعكس تصنيف وكال قو علم يمك سرط لكن تعكس مخاطر اصاب سرط مستوى مع يراع تقييم مخاطر تجر وكال انواع غذاء الخ يشكل تصنيف قو مجموع اعلى مستوى حال جود ولك اصاب بشر سرط مقنع اصاب حيوان تجارب قال دكتور مار رنامج دراس متخصص وكال دول بحوث سرط نتايج محدود طابع بشر الال محدود كيف حدوث توكد ضرور اجراء مزيد بحوث تحس فهم خصوص استهل اسبارتام يشكل اخطار سرطن تحدد تقييم مخاطر تجر لجن خبراء مشترك مدى احتمال حدوث نوع مع ظروف مستو معين ليس امر عاد تراع لجن خبراء مشترك تصنيف وكال دول بحوث سرط مداول قال دكتور معز رييس وحد معايير مشور علم بشء اغذ تغذ منظم لقد نظر لجن خبراء مشترك متعلق مخاطر اصاب سرط وارد دراس حيوان خلص تشير جود ارتباط استهل اسبارتام اصاب سرط بشر مقنع اضاف انن حاج دراس نوع افضل اجراء متابع اطول واستبيان غذاء متكرر مجموع قايم ونح حاج تجارب منضبط دراس مسار ميكانيك الصل ضبط انسول متلازم ايض داء سيم يتعلق سرطن واستند تقييم اثر اسبارتام اجر وكال دول بحوث سرط لجن خبراء مشترك يان علم طايف متنوع ورق خاضع استعراض اقر تقارير حكوم دراس اغراض تنظيم وقد استعرض دراس واتخذ لجنت خطو لضما استقلال تقييم موثوق ستواصل وكال دول بحوث سرط منظم رصد جديد تشجيع افرق بحث مستقل اجراء مزيد دراس بشء علاق محتمل اسبارتام اثار صح مستهلك اتصال اعلام véronique terrasse communication officeriarc استفسار سايل اعلام مختار ملخص نتايج تقييم اسبارتام اجتماع رابع ثلاث ماء برنامج دراس وكال دول بحوث اجتماع سادس تسع للجن خبراء مشترك منظم اغذ زراع منظم الصح عالم معن مواد مضاف\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the preprocessed texts\n",
    "for i, text in enumerate(preprocessed_texts):\n",
    "    print(f'Preprocessed Text {i+1}:\\n{text}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f6803",
   "metadata": {},
   "source": [
    "## C. Model Training <a id='tra'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e29f5d",
   "metadata": {},
   "source": [
    "We train four different recurrent neural network (RNN) architectures - RNN, Bidirectional RNN, GRU, and LSTM - on the preprocessed dataset. We tune hyperparameters to optimize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1550c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training \n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, scores):\n",
    "        self.texts = texts\n",
    "        self.scores = scores\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.scores[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fbf8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "651a79ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BiRNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839a9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8fc88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66085912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for texts, scores in dataloader:\n",
    "            texts = texts.float()\n",
    "            scores = scores.float().view(-1, 1)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, scores)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643976aa",
   "metadata": {},
   "source": [
    "## D. Model Evaluation<a id='eva'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5109d5",
   "metadata": {},
   "source": [
    "We evaluate the trained models using standard metrics such as Mean Squared Error (MSE) and Mean Absolute Error (MAE). Additionally, we may consider other metrics like BLEU score for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a238ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for texts, scores in dataloader:\n",
    "            texts = texts.float()\n",
    "            scores = scores.float().view(-1, 1)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            predictions.extend(outputs.numpy())\n",
    "            actuals.extend(scores.numpy())\n",
    "\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    return mse, mae # Return the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a39a313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample preprocessed text data (vectorized for the sake of example)\n",
    "preprocessed_texts = [np.random.rand(10, 100) for _ in range(2)]  # Example 2 texts, each with 10 words, 100-dim embeddings\n",
    "scores = [6, 7.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe13030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_10868\\2412606312.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  train_texts = torch.tensor(train_texts, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "train_texts, test_texts, train_scores, test_scores = train_test_split(preprocessed_texts, scores, test_size=0.2, random_state=42)\n",
    "\n",
    "# Converting lists of numpy arrays to PyTorch tensors\n",
    "train_texts = torch.tensor(train_texts, dtype=torch.float32)\n",
    "test_texts = torch.tensor(test_texts, dtype=torch.float32)\n",
    "train_scores = torch.tensor(train_scores, dtype=torch.float32)\n",
    "test_scores = torch.tensor(test_scores, dtype=torch.float32)\n",
    "\n",
    "# Creating custom dataset instances for training and testing data\n",
    "train_dataset = TextDataset(train_texts, train_scores)\n",
    "test_dataset = TextDataset(test_texts, test_scores)\n",
    "\n",
    "# Creating data loaders for training and testing datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "022c6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters\n",
    "input_size = 100 \n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initializing the different models to be trained\n",
    "models = {\n",
    "    'RNN': RNNModel(input_size, hidden_size, output_size),\n",
    "    'BiRNN': BiRNNModel(input_size, hidden_size, output_size),\n",
    "    'GRU': GRUModel(input_size, hidden_size, output_size),\n",
    "    'LSTM': LSTMModel(input_size, hidden_size, output_size)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df4ef8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN model...\n",
      "Epoch [1/10], Loss: 37.9811\n",
      "Epoch [2/10], Loss: 31.4718\n",
      "Epoch [3/10], Loss: 25.8470\n",
      "Epoch [4/10], Loss: 21.0031\n",
      "Epoch [5/10], Loss: 16.8329\n",
      "Epoch [6/10], Loss: 13.2703\n",
      "Epoch [7/10], Loss: 10.2764\n",
      "Epoch [8/10], Loss: 7.8106\n",
      "Epoch [9/10], Loss: 5.8205\n",
      "Epoch [10/10], Loss: 4.2441\n",
      "RNN model Evaluation:\n",
      " - Mean Squared Error: 13.7539\n",
      " - Mean Absolute Error: 3.7086\n",
      "Training BiRNN model...\n",
      "Epoch [1/10], Loss: 37.3675\n",
      "Epoch [2/10], Loss: 30.4698\n",
      "Epoch [3/10], Loss: 24.3927\n",
      "Epoch [4/10], Loss: 19.1087\n",
      "Epoch [5/10], Loss: 14.5885\n",
      "Epoch [6/10], Loss: 10.8007\n",
      "Epoch [7/10], Loss: 7.7029\n",
      "Epoch [8/10], Loss: 5.2396\n",
      "Epoch [9/10], Loss: 3.3465\n",
      "Epoch [10/10], Loss: 1.9548\n",
      "BiRNN model Evaluation:\n",
      " - Mean Squared Error: 9.9278\n",
      " - Mean Absolute Error: 3.1508\n",
      "Training GRU model...\n",
      "Epoch [1/10], Loss: 32.6675\n",
      "Epoch [2/10], Loss: 28.4278\n",
      "Epoch [3/10], Loss: 24.5070\n",
      "Epoch [4/10], Loss: 20.8555\n",
      "Epoch [5/10], Loss: 17.4465\n",
      "Epoch [6/10], Loss: 14.2802\n",
      "Epoch [7/10], Loss: 11.3831\n",
      "Epoch [8/10], Loss: 8.7984\n",
      "Epoch [9/10], Loss: 6.5710\n",
      "Epoch [10/10], Loss: 4.7283\n",
      "GRU model Evaluation:\n",
      " - Mean Squared Error: 12.2492\n",
      " - Mean Absolute Error: 3.4999\n",
      "Training LSTM model...\n",
      "Epoch [1/10], Loss: 34.9040\n",
      "Epoch [2/10], Loss: 32.3426\n",
      "Epoch [3/10], Loss: 29.8333\n",
      "Epoch [4/10], Loss: 27.2605\n",
      "Epoch [5/10], Loss: 24.5536\n",
      "Epoch [6/10], Loss: 21.6918\n",
      "Epoch [7/10], Loss: 18.7145\n",
      "Epoch [8/10], Loss: 15.7322\n",
      "Epoch [9/10], Loss: 12.9026\n",
      "Epoch [10/10], Loss: 10.3681\n",
      "LSTM model Evaluation:\n",
      " - Mean Squared Error: 20.0733\n",
      " - Mean Absolute Error: 4.4803\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating each model\n",
    "for model_name, model in models.items():\n",
    "    print(f'Training {model_name} model...')\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_model(model, train_dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "    mse, mae = evaluate_model(model, test_dataloader)\n",
    "    print(f'{model_name} model Evaluation:')\n",
    "    print(f' - Mean Squared Error: {mse:.4f}')\n",
    "    print(f' - Mean Absolute Error: {mae:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
